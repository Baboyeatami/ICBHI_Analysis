{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c7233efb-8845-4624-bed2-d8241ac67b33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 1. Extracting Dual Features (With Augmentation) ---\n",
      "Processing 193 files with augmentation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 193/193 [00:35<00:00,  5.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Shape: (3520, 103, 500, 1)\n",
      "Labels: ['Crackle' 'Normal' 'Wheeze']\n",
      "\n",
      "--- 2. Starting 5-Fold Grouped Cross Validation ---\n",
      "\n",
      "Training Fold 1...\n",
      "Epoch 1/30\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 533ms/step - accuracy: 0.5132 - loss: 1.0208 - val_accuracy: 0.5085 - val_loss: 1.0875\n",
      "Epoch 2/30\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 540ms/step - accuracy: 0.5060 - loss: 1.0050 - val_accuracy: 0.5085 - val_loss: 1.0720\n",
      "Epoch 3/30\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 535ms/step - accuracy: 0.5231 - loss: 0.9827 - val_accuracy: 0.5056 - val_loss: 1.0713\n",
      "Epoch 4/30\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 540ms/step - accuracy: 0.5455 - loss: 0.9738 - val_accuracy: 0.5085 - val_loss: 1.1246\n",
      "Epoch 5/30\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 529ms/step - accuracy: 0.5569 - loss: 0.9652 - val_accuracy: 0.4718 - val_loss: 1.0330\n",
      "Epoch 6/30\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 536ms/step - accuracy: 0.5754 - loss: 0.9386 - val_accuracy: 0.4675 - val_loss: 1.0422\n",
      "Epoch 7/30\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 529ms/step - accuracy: 0.5789 - loss: 0.9345 - val_accuracy: 0.4576 - val_loss: 1.1149\n",
      "Epoch 8/30\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 532ms/step - accuracy: 0.6014 - loss: 0.9127 - val_accuracy: 0.5085 - val_loss: 1.0293\n",
      "Epoch 9/30\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 526ms/step - accuracy: 0.5996 - loss: 0.9031 - val_accuracy: 0.4816 - val_loss: 1.0584\n",
      "Epoch 10/30\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 530ms/step - accuracy: 0.6092 - loss: 0.8964 - val_accuracy: 0.4661 - val_loss: 1.1309\n",
      "Epoch 11/30\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 536ms/step - accuracy: 0.6142 - loss: 0.8871 - val_accuracy: 0.4167 - val_loss: 1.2521\n",
      "Epoch 12/30\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 530ms/step - accuracy: 0.6106 - loss: 0.8842 - val_accuracy: 0.5113 - val_loss: 1.0309\n",
      "Epoch 13/30\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 534ms/step - accuracy: 0.6195 - loss: 0.8646 - val_accuracy: 0.5311 - val_loss: 0.9841\n",
      "Epoch 14/30\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 535ms/step - accuracy: 0.6177 - loss: 0.8596 - val_accuracy: 0.5325 - val_loss: 1.0138\n",
      "Epoch 15/30\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 530ms/step - accuracy: 0.6387 - loss: 0.8352 - val_accuracy: 0.4718 - val_loss: 1.1439\n",
      "Epoch 16/30\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 530ms/step - accuracy: 0.6422 - loss: 0.8345 - val_accuracy: 0.5155 - val_loss: 1.0208\n",
      "Epoch 17/30\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 535ms/step - accuracy: 0.6504 - loss: 0.8104 - val_accuracy: 0.5551 - val_loss: 0.9787\n",
      "Epoch 18/30\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 528ms/step - accuracy: 0.6412 - loss: 0.8170 - val_accuracy: 0.5254 - val_loss: 1.0286\n",
      "Epoch 19/30\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 534ms/step - accuracy: 0.6671 - loss: 0.7788 - val_accuracy: 0.5240 - val_loss: 1.0829\n",
      "Epoch 20/30\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 525ms/step - accuracy: 0.6650 - loss: 0.7747 - val_accuracy: 0.5169 - val_loss: 1.0348\n",
      "Epoch 21/30\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 531ms/step - accuracy: 0.6380 - loss: 0.8025 - val_accuracy: 0.5113 - val_loss: 1.0008\n",
      "Epoch 22/30\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 525ms/step - accuracy: 0.6753 - loss: 0.7557 - val_accuracy: 0.4746 - val_loss: 1.1135\n",
      "Epoch 23/30\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 530ms/step - accuracy: 0.6824 - loss: 0.7430 - val_accuracy: 0.5480 - val_loss: 1.0162\n",
      "Epoch 24/30\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 525ms/step - accuracy: 0.6839 - loss: 0.7322 - val_accuracy: 0.5593 - val_loss: 1.0269\n",
      "Epoch 25/30\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 531ms/step - accuracy: 0.6917 - loss: 0.7196 - val_accuracy: 0.5212 - val_loss: 1.0401\n",
      "Epoch 26/30\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 529ms/step - accuracy: 0.7159 - loss: 0.6868 - val_accuracy: 0.5424 - val_loss: 1.1333\n",
      "Epoch 27/30\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 538ms/step - accuracy: 0.7183 - loss: 0.6535 - val_accuracy: 0.5621 - val_loss: 1.0715\n",
      "Epoch 28/30\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 532ms/step - accuracy: 0.7287 - loss: 0.6446 - val_accuracy: 0.4901 - val_loss: 1.2426\n",
      "Epoch 29/30\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 529ms/step - accuracy: 0.7344 - loss: 0.6390 - val_accuracy: 0.5480 - val_loss: 1.0894\n",
      "Epoch 30/30\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 537ms/step - accuracy: 0.7461 - loss: 0.6231 - val_accuracy: 0.5424 - val_loss: 1.1574\n",
      "Fold 1 Accuracy: 0.5424\n",
      "\n",
      "Training Fold 2...\n",
      "Epoch 1/30\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 538ms/step - accuracy: 0.4982 - loss: 1.0342 - val_accuracy: 0.5086 - val_loss: 1.0837\n",
      "Epoch 2/30\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 555ms/step - accuracy: 0.5096 - loss: 1.0176 - val_accuracy: 0.5086 - val_loss: 1.1941\n",
      "Epoch 3/30\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 565ms/step - accuracy: 0.5099 - loss: 1.0082 - val_accuracy: 0.5086 - val_loss: 1.1612\n",
      "Epoch 4/30\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 573ms/step - accuracy: 0.5131 - loss: 0.9819 - val_accuracy: 0.5043 - val_loss: 1.0102\n",
      "Epoch 5/30\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 576ms/step - accuracy: 0.5057 - loss: 0.9877 - val_accuracy: 0.4743 - val_loss: 0.9538\n",
      "Epoch 6/30\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 579ms/step - accuracy: 0.5262 - loss: 0.9609 - val_accuracy: 0.5000 - val_loss: 0.9584\n",
      "Epoch 7/30\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 572ms/step - accuracy: 0.5450 - loss: 0.9325 - val_accuracy: 0.4929 - val_loss: 1.0061\n",
      "Epoch 8/30\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 575ms/step - accuracy: 0.5376 - loss: 0.9559 - val_accuracy: 0.5057 - val_loss: 0.9824\n",
      "Epoch 9/30\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 584ms/step - accuracy: 0.5819 - loss: 0.9033 - val_accuracy: 0.5671 - val_loss: 0.9049\n",
      "Epoch 10/30\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 581ms/step - accuracy: 0.5833 - loss: 0.8944 - val_accuracy: 0.5471 - val_loss: 0.9622\n",
      "Epoch 11/30\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 580ms/step - accuracy: 0.6142 - loss: 0.8277 - val_accuracy: 0.5843 - val_loss: 0.9058\n",
      "Epoch 12/30\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 578ms/step - accuracy: 0.6521 - loss: 0.7806 - val_accuracy: 0.5386 - val_loss: 0.9715\n",
      "Epoch 13/30\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 577ms/step - accuracy: 0.6968 - loss: 0.7119 - val_accuracy: 0.5429 - val_loss: 1.0311\n",
      "Epoch 14/30\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 580ms/step - accuracy: 0.7082 - loss: 0.6871 - val_accuracy: 0.5829 - val_loss: 0.9732\n",
      "Epoch 15/30\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 571ms/step - accuracy: 0.7525 - loss: 0.6094 - val_accuracy: 0.5414 - val_loss: 1.0936\n",
      "Epoch 16/30\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 585ms/step - accuracy: 0.7901 - loss: 0.5275 - val_accuracy: 0.6171 - val_loss: 0.9640\n",
      "Epoch 17/30\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 581ms/step - accuracy: 0.7986 - loss: 0.5063 - val_accuracy: 0.5586 - val_loss: 1.0068\n",
      "Epoch 18/30\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 584ms/step - accuracy: 0.8337 - loss: 0.4304 - val_accuracy: 0.6429 - val_loss: 0.9822\n",
      "Epoch 19/30\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 581ms/step - accuracy: 0.8535 - loss: 0.3800 - val_accuracy: 0.6400 - val_loss: 1.0220\n",
      "Epoch 20/30\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 578ms/step - accuracy: 0.8940 - loss: 0.3204 - val_accuracy: 0.5929 - val_loss: 1.2333\n",
      "Epoch 21/30\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 569ms/step - accuracy: 0.8940 - loss: 0.3020 - val_accuracy: 0.4986 - val_loss: 1.5518\n",
      "Epoch 22/30\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 575ms/step - accuracy: 0.8975 - loss: 0.2885 - val_accuracy: 0.5743 - val_loss: 1.4030\n",
      "Epoch 23/30\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 574ms/step - accuracy: 0.9216 - loss: 0.2188 - val_accuracy: 0.5614 - val_loss: 1.4610\n",
      "Epoch 24/30\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 571ms/step - accuracy: 0.9316 - loss: 0.2066 - val_accuracy: 0.5543 - val_loss: 1.5792\n",
      "Epoch 25/30\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 578ms/step - accuracy: 0.9443 - loss: 0.1747 - val_accuracy: 0.5900 - val_loss: 1.4263\n",
      "Epoch 26/30\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 577ms/step - accuracy: 0.9493 - loss: 0.1472 - val_accuracy: 0.6129 - val_loss: 1.5625\n",
      "Epoch 27/30\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 564ms/step - accuracy: 0.9628 - loss: 0.1175 - val_accuracy: 0.5529 - val_loss: 1.7115\n",
      "Epoch 28/30\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 578ms/step - accuracy: 0.9567 - loss: 0.1241 - val_accuracy: 0.6214 - val_loss: 1.5643\n",
      "Epoch 29/30\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 578ms/step - accuracy: 0.9635 - loss: 0.1048 - val_accuracy: 0.5886 - val_loss: 1.6477\n",
      "Epoch 30/30\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 577ms/step - accuracy: 0.9745 - loss: 0.0811 - val_accuracy: 0.5900 - val_loss: 1.9193\n",
      "Fold 2 Accuracy: 0.5900\n",
      "\n",
      "Training Fold 3...\n",
      "Epoch 1/30\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 606ms/step - accuracy: 0.4900 - loss: 1.0275 - val_accuracy: 0.5225 - val_loss: 1.0821\n",
      "Epoch 2/30\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 606ms/step - accuracy: 0.5135 - loss: 0.9980 - val_accuracy: 0.5225 - val_loss: 1.1335\n",
      "Epoch 3/30\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 619ms/step - accuracy: 0.5292 - loss: 0.9736 - val_accuracy: 0.6081 - val_loss: 1.0188\n",
      "Epoch 4/30\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 607ms/step - accuracy: 0.5499 - loss: 0.9579 - val_accuracy: 0.5927 - val_loss: 1.0669\n",
      "Epoch 5/30\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 612ms/step - accuracy: 0.5520 - loss: 0.9428 - val_accuracy: 0.5857 - val_loss: 1.0258\n",
      "Epoch 6/30\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 596ms/step - accuracy: 0.5737 - loss: 0.9234 - val_accuracy: 0.5239 - val_loss: 1.0396\n",
      "Epoch 7/30\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 604ms/step - accuracy: 0.5937 - loss: 0.9083 - val_accuracy: 0.5941 - val_loss: 0.9650\n",
      "Epoch 8/30\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 598ms/step - accuracy: 0.6311 - loss: 0.8562 - val_accuracy: 0.6236 - val_loss: 0.9556\n",
      "Epoch 9/30\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 595ms/step - accuracy: 0.6296 - loss: 0.8620 - val_accuracy: 0.6292 - val_loss: 0.9233\n",
      "Epoch 10/30\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 593ms/step - accuracy: 0.6385 - loss: 0.8238 - val_accuracy: 0.6292 - val_loss: 0.9713\n",
      "Epoch 11/30\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 592ms/step - accuracy: 0.6695 - loss: 0.7646 - val_accuracy: 0.5618 - val_loss: 1.0030\n",
      "Epoch 12/30\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 589ms/step - accuracy: 0.6713 - loss: 0.7583 - val_accuracy: 0.5997 - val_loss: 0.9911\n",
      "Epoch 13/30\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 593ms/step - accuracy: 0.6959 - loss: 0.7259 - val_accuracy: 0.5955 - val_loss: 1.0016\n",
      "Epoch 14/30\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 590ms/step - accuracy: 0.6973 - loss: 0.6769 - val_accuracy: 0.5604 - val_loss: 1.1234\n",
      "Epoch 15/30\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 589ms/step - accuracy: 0.7365 - loss: 0.6378 - val_accuracy: 0.5857 - val_loss: 1.1687\n",
      "Epoch 16/30\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 588ms/step - accuracy: 0.7618 - loss: 0.5805 - val_accuracy: 0.5140 - val_loss: 1.2246\n",
      "Epoch 17/30\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 588ms/step - accuracy: 0.7667 - loss: 0.5744 - val_accuracy: 0.5295 - val_loss: 1.1927\n",
      "Epoch 18/30\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 585ms/step - accuracy: 0.7781 - loss: 0.5409 - val_accuracy: 0.4761 - val_loss: 1.4426\n",
      "Epoch 19/30\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 587ms/step - accuracy: 0.8031 - loss: 0.5088 - val_accuracy: 0.4888 - val_loss: 1.3223\n",
      "Epoch 20/30\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 582ms/step - accuracy: 0.8287 - loss: 0.4423 - val_accuracy: 0.5154 - val_loss: 1.3534\n",
      "Epoch 21/30\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 583ms/step - accuracy: 0.8479 - loss: 0.3933 - val_accuracy: 0.6067 - val_loss: 1.5554\n",
      "Epoch 22/30\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 581ms/step - accuracy: 0.8465 - loss: 0.3983 - val_accuracy: 0.6067 - val_loss: 1.4328\n",
      "Epoch 23/30\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 582ms/step - accuracy: 0.8597 - loss: 0.3765 - val_accuracy: 0.5899 - val_loss: 1.6906\n",
      "Epoch 24/30\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 581ms/step - accuracy: 0.8942 - loss: 0.2819 - val_accuracy: 0.5281 - val_loss: 1.8291\n",
      "Epoch 25/30\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 582ms/step - accuracy: 0.9056 - loss: 0.2582 - val_accuracy: 0.4424 - val_loss: 1.7642\n",
      "Epoch 26/30\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 581ms/step - accuracy: 0.9192 - loss: 0.2124 - val_accuracy: 0.5463 - val_loss: 1.9819\n",
      "Epoch 27/30\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 581ms/step - accuracy: 0.9359 - loss: 0.1702 - val_accuracy: 0.5183 - val_loss: 1.9546\n",
      "Epoch 28/30\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 582ms/step - accuracy: 0.9455 - loss: 0.1533 - val_accuracy: 0.5056 - val_loss: 2.3360\n",
      "Epoch 29/30\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 581ms/step - accuracy: 0.9519 - loss: 0.1419 - val_accuracy: 0.5674 - val_loss: 2.1348\n",
      "Epoch 30/30\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 580ms/step - accuracy: 0.9427 - loss: 0.1615 - val_accuracy: 0.5815 - val_loss: 2.3272\n",
      "Fold 3 Accuracy: 0.5815\n",
      "\n",
      "Training Fold 4...\n",
      "Epoch 1/30\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 628ms/step - accuracy: 0.5075 - loss: 1.0370 - val_accuracy: 0.5057 - val_loss: 1.0431\n",
      "Epoch 2/30\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 612ms/step - accuracy: 0.5096 - loss: 1.0242 - val_accuracy: 0.5057 - val_loss: 1.0548\n",
      "Epoch 3/30\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 611ms/step - accuracy: 0.5121 - loss: 1.0073 - val_accuracy: 0.5057 - val_loss: 1.0512\n",
      "Epoch 4/30\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 609ms/step - accuracy: 0.5270 - loss: 0.9932 - val_accuracy: 0.5057 - val_loss: 1.0598\n",
      "Epoch 5/30\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 613ms/step - accuracy: 0.5494 - loss: 0.9664 - val_accuracy: 0.5526 - val_loss: 1.0288\n",
      "Epoch 6/30\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 609ms/step - accuracy: 0.5323 - loss: 0.9822 - val_accuracy: 0.5057 - val_loss: 0.9955\n",
      "Epoch 7/30\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 612ms/step - accuracy: 0.5721 - loss: 0.9373 - val_accuracy: 0.5142 - val_loss: 1.0138\n",
      "Epoch 8/30\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 611ms/step - accuracy: 0.5987 - loss: 0.8909 - val_accuracy: 0.4986 - val_loss: 1.0530\n",
      "Epoch 9/30\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 612ms/step - accuracy: 0.6261 - loss: 0.8383 - val_accuracy: 0.5923 - val_loss: 0.9796\n",
      "Epoch 10/30\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 611ms/step - accuracy: 0.6353 - loss: 0.8276 - val_accuracy: 0.4815 - val_loss: 1.0886\n",
      "Epoch 11/30\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 612ms/step - accuracy: 0.6605 - loss: 0.7853 - val_accuracy: 0.5653 - val_loss: 0.9851\n",
      "Epoch 12/30\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 608ms/step - accuracy: 0.6925 - loss: 0.7443 - val_accuracy: 0.5412 - val_loss: 1.0216\n",
      "Epoch 13/30\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 611ms/step - accuracy: 0.7031 - loss: 0.7162 - val_accuracy: 0.5099 - val_loss: 1.1352\n",
      "Epoch 14/30\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 608ms/step - accuracy: 0.7319 - loss: 0.6530 - val_accuracy: 0.5284 - val_loss: 1.2266\n",
      "Epoch 15/30\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 611ms/step - accuracy: 0.7362 - loss: 0.6560 - val_accuracy: 0.4858 - val_loss: 1.1904\n",
      "Epoch 16/30\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 609ms/step - accuracy: 0.7642 - loss: 0.5879 - val_accuracy: 0.5270 - val_loss: 1.4160\n",
      "Epoch 17/30\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 610ms/step - accuracy: 0.7834 - loss: 0.5569 - val_accuracy: 0.4830 - val_loss: 1.2803\n",
      "Epoch 18/30\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 609ms/step - accuracy: 0.8015 - loss: 0.5145 - val_accuracy: 0.4872 - val_loss: 1.3535\n",
      "Epoch 19/30\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 612ms/step - accuracy: 0.8001 - loss: 0.4978 - val_accuracy: 0.5213 - val_loss: 1.2465\n",
      "Epoch 20/30\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 609ms/step - accuracy: 0.8196 - loss: 0.4607 - val_accuracy: 0.4929 - val_loss: 1.6925\n",
      "Epoch 21/30\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 610ms/step - accuracy: 0.8477 - loss: 0.4186 - val_accuracy: 0.4858 - val_loss: 1.6884\n",
      "Epoch 22/30\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 610ms/step - accuracy: 0.8498 - loss: 0.3856 - val_accuracy: 0.5185 - val_loss: 1.6086\n",
      "Epoch 23/30\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 609ms/step - accuracy: 0.8555 - loss: 0.3836 - val_accuracy: 0.4943 - val_loss: 1.4250\n",
      "Epoch 24/30\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 609ms/step - accuracy: 0.8977 - loss: 0.2867 - val_accuracy: 0.4815 - val_loss: 1.7871\n",
      "Epoch 25/30\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 612ms/step - accuracy: 0.9048 - loss: 0.2683 - val_accuracy: 0.4503 - val_loss: 1.8241\n",
      "Epoch 26/30\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 607ms/step - accuracy: 0.9102 - loss: 0.2545 - val_accuracy: 0.4474 - val_loss: 1.8394\n",
      "Epoch 27/30\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 611ms/step - accuracy: 0.9148 - loss: 0.2488 - val_accuracy: 0.4673 - val_loss: 1.8745\n",
      "Epoch 28/30\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 609ms/step - accuracy: 0.9336 - loss: 0.1952 - val_accuracy: 0.4787 - val_loss: 2.1360\n",
      "Epoch 29/30\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 610ms/step - accuracy: 0.9418 - loss: 0.1663 - val_accuracy: 0.5014 - val_loss: 2.2420\n",
      "Epoch 30/30\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 609ms/step - accuracy: 0.9322 - loss: 0.1887 - val_accuracy: 0.4929 - val_loss: 2.0825\n",
      "Fold 4 Accuracy: 0.4929\n",
      "\n",
      "Training Fold 5...\n",
      "Epoch 1/30\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 579ms/step - accuracy: 0.4996 - loss: 1.0317 - val_accuracy: 0.5057 - val_loss: 1.0542\n",
      "Epoch 2/30\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 582ms/step - accuracy: 0.5142 - loss: 1.0134 - val_accuracy: 0.5057 - val_loss: 1.3041\n",
      "Epoch 3/30\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 582ms/step - accuracy: 0.5382 - loss: 0.9815 - val_accuracy: 0.5057 - val_loss: 1.3525\n",
      "Epoch 4/30\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 578ms/step - accuracy: 0.5432 - loss: 0.9659 - val_accuracy: 0.5029 - val_loss: 1.0874\n",
      "Epoch 5/30\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 576ms/step - accuracy: 0.5797 - loss: 0.9206 - val_accuracy: 0.5675 - val_loss: 1.1129\n",
      "Epoch 6/30\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 573ms/step - accuracy: 0.5825 - loss: 0.9270 - val_accuracy: 0.5460 - val_loss: 1.0897\n",
      "Epoch 7/30\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 576ms/step - accuracy: 0.5829 - loss: 0.9075 - val_accuracy: 0.5402 - val_loss: 1.1136\n",
      "Epoch 8/30\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 572ms/step - accuracy: 0.6016 - loss: 0.8853 - val_accuracy: 0.5661 - val_loss: 0.9975\n",
      "Epoch 9/30\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 579ms/step - accuracy: 0.6211 - loss: 0.8624 - val_accuracy: 0.5302 - val_loss: 1.0154\n",
      "Epoch 10/30\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 566ms/step - accuracy: 0.6317 - loss: 0.8355 - val_accuracy: 0.5345 - val_loss: 1.0582\n",
      "Epoch 11/30\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 572ms/step - accuracy: 0.6473 - loss: 0.8138 - val_accuracy: 0.5532 - val_loss: 1.1587\n",
      "Epoch 12/30\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 576ms/step - accuracy: 0.6643 - loss: 0.7819 - val_accuracy: 0.5776 - val_loss: 1.1069\n",
      "Epoch 13/30\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 576ms/step - accuracy: 0.6629 - loss: 0.7905 - val_accuracy: 0.5589 - val_loss: 1.1099\n",
      "Epoch 14/30\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 577ms/step - accuracy: 0.6877 - loss: 0.7456 - val_accuracy: 0.5776 - val_loss: 1.1568\n",
      "Epoch 15/30\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 575ms/step - accuracy: 0.6962 - loss: 0.7336 - val_accuracy: 0.5661 - val_loss: 1.1028\n",
      "Epoch 16/30\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 558ms/step - accuracy: 0.6898 - loss: 0.7487 - val_accuracy: 0.5417 - val_loss: 1.1020\n",
      "Epoch 17/30\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 557ms/step - accuracy: 0.7015 - loss: 0.6976 - val_accuracy: 0.6006 - val_loss: 1.1350\n",
      "Epoch 18/30\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 557ms/step - accuracy: 0.7047 - loss: 0.7123 - val_accuracy: 0.5532 - val_loss: 1.2219\n",
      "Epoch 19/30\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 557ms/step - accuracy: 0.7312 - loss: 0.6610 - val_accuracy: 0.6106 - val_loss: 1.0544\n",
      "Epoch 20/30\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 557ms/step - accuracy: 0.7472 - loss: 0.6172 - val_accuracy: 0.5489 - val_loss: 1.2946\n",
      "Epoch 21/30\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 560ms/step - accuracy: 0.7440 - loss: 0.6131 - val_accuracy: 0.5647 - val_loss: 1.1269\n",
      "Epoch 22/30\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 559ms/step - accuracy: 0.7482 - loss: 0.6013 - val_accuracy: 0.6135 - val_loss: 1.1905\n",
      "Epoch 23/30\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 558ms/step - accuracy: 0.7585 - loss: 0.5727 - val_accuracy: 0.5862 - val_loss: 1.1982\n",
      "Epoch 24/30\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 557ms/step - accuracy: 0.7702 - loss: 0.5532 - val_accuracy: 0.5977 - val_loss: 1.5907\n",
      "Epoch 25/30\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 562ms/step - accuracy: 0.7695 - loss: 0.5658 - val_accuracy: 0.6034 - val_loss: 1.3002\n",
      "Epoch 26/30\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 562ms/step - accuracy: 0.7921 - loss: 0.5153 - val_accuracy: 0.6006 - val_loss: 1.3273\n",
      "Epoch 27/30\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 561ms/step - accuracy: 0.7865 - loss: 0.5273 - val_accuracy: 0.6034 - val_loss: 1.4966\n",
      "Epoch 28/30\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 562ms/step - accuracy: 0.7914 - loss: 0.4918 - val_accuracy: 0.6236 - val_loss: 1.4975\n",
      "Epoch 29/30\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 562ms/step - accuracy: 0.7978 - loss: 0.4998 - val_accuracy: 0.6164 - val_loss: 1.3937\n",
      "Epoch 30/30\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 562ms/step - accuracy: 0.8088 - loss: 0.4738 - val_accuracy: 0.6221 - val_loss: 1.5064\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 5 Accuracy: 0.6221\n",
      "\n",
      "--- Cross-Validation Results ---\n",
      "Average Accuracy: 0.5658\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import librosa\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, BatchNormalization, ReLU, Reshape, Bidirectional, LSTM, Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.model_selection import StratifiedGroupKFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import classification_report\n",
    "from tqdm import tqdm\n",
    "\n",
    "# --- CONFIGURATION ---\n",
    "DATASET_DIR = 'dataset' \n",
    "SAVE_DIR = 'results_dual_pipeline'\n",
    "os.makedirs(SAVE_DIR, exist_ok=True)\n",
    "\n",
    "SAMPLE_RATE = 16000\n",
    "FRAME_LENGTH = 0.025\n",
    "FRAME_STRIDE = 0.010\n",
    "N_MFCC = 13\n",
    "N_COCHLEAGRAM_BANDS = 64\n",
    "F_MIN = 100\n",
    "F_MAX = 2500\n",
    "MAX_PAD_LEN = 500\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 30\n",
    "\n",
    "def get_label(crackle, wheeze):\n",
    "    if crackle == 0 and wheeze == 0: return 'Normal'\n",
    "    if crackle == 1 and wheeze == 0: return 'Crackle'\n",
    "    if crackle == 0 and wheeze == 1: return 'Wheeze'\n",
    "    return 'Wheeze'\n",
    "\n",
    "# --- 1. AUGMENTATION & FEATURE EXTRACTION ---\n",
    "\n",
    "def augment_audio(y, sr):\n",
    "    \"\"\"\n",
    "    Generates 3 augmented versions of the original audio segment.\n",
    "    \"\"\"\n",
    "    augmented_versions = []\n",
    "    \n",
    "    # A. Time Stretch\n",
    "    try:\n",
    "        rate = np.random.uniform(0.8, 1.2)\n",
    "        y_stretch = librosa.effects.time_stretch(y, rate=rate)\n",
    "        # Fix length back to original\n",
    "        if len(y_stretch) > len(y):\n",
    "            y_stretch = y_stretch[:len(y)]\n",
    "        else:\n",
    "            y_stretch = np.pad(y_stretch, (0, len(y) - len(y_stretch)))\n",
    "        augmented_versions.append(y_stretch)\n",
    "    except:\n",
    "        pass # Skip if stretch fails on tiny clips\n",
    "    \n",
    "    # B. Pitch Shift\n",
    "    try:\n",
    "        steps = np.random.uniform(-2, 2)\n",
    "        y_shift = librosa.effects.pitch_shift(y, sr=sr, n_steps=steps)\n",
    "        augmented_versions.append(y_shift)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    # C. Noise Injection\n",
    "    try:\n",
    "        noise_amp = 0.005 * np.random.uniform() * np.amax(y)\n",
    "        y_noise = y.astype('float64') + noise_amp * np.random.normal(size=y.shape[0])\n",
    "        augmented_versions.append(y_noise)\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    return augmented_versions\n",
    "\n",
    "def extract_dual_features(y, sr):\n",
    "    \"\"\"\n",
    "    Extracts Stacked MFCCs + Cochleogram from a raw audio array (y).\n",
    "    \"\"\"\n",
    "    # Padding/Truncating\n",
    "    target_len = int(MAX_PAD_LEN * (FRAME_STRIDE * SAMPLE_RATE))\n",
    "    if len(y) < target_len:\n",
    "        y = np.pad(y, (0, target_len - len(y)))\n",
    "    else:\n",
    "        y = y[:target_len]\n",
    "\n",
    "    # Pipeline A: MFCCs\n",
    "    mfcc = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=N_MFCC, n_fft=int(FRAME_LENGTH*sr), hop_length=int(FRAME_STRIDE*sr))\n",
    "    delta_mfcc = librosa.feature.delta(mfcc)\n",
    "    delta2_mfcc = librosa.feature.delta(mfcc, order=2)\n",
    "    mfcc_combined = np.concatenate((mfcc, delta_mfcc, delta2_mfcc), axis=0)\n",
    "\n",
    "    # Pipeline B: Cochleogram (Mel-Spectrogram)\n",
    "    cochleogram = librosa.feature.melspectrogram(y=y, sr=sr, n_mels=N_COCHLEAGRAM_BANDS, fmin=F_MIN, fmax=F_MAX, n_fft=int(FRAME_LENGTH*sr), hop_length=int(FRAME_STRIDE*sr))\n",
    "    cochleogram = librosa.power_to_db(cochleogram, ref=np.max)\n",
    "\n",
    "    # Fusion\n",
    "    min_time = min(mfcc_combined.shape[1], cochleogram.shape[1])\n",
    "    mfcc_combined = mfcc_combined[:, :min_time]\n",
    "    cochleogram = cochleogram[:, :min_time]\n",
    "    fused_features = np.concatenate((mfcc_combined, cochleogram), axis=0)\n",
    "    \n",
    "    # Pad to MAX_PAD_LEN (Time Axis)\n",
    "    if fused_features.shape[1] < MAX_PAD_LEN:\n",
    "        pad_width = MAX_PAD_LEN - fused_features.shape[1]\n",
    "        fused_features = np.pad(fused_features, ((0,0), (0, pad_width)), mode='constant')\n",
    "    else:\n",
    "        fused_features = fused_features[:, :MAX_PAD_LEN]\n",
    "        \n",
    "    # Z-Score Normalization\n",
    "    mean = np.mean(fused_features)\n",
    "    std = np.std(fused_features)\n",
    "    fused_features = (fused_features - mean) / (std + 1e-6)\n",
    "    \n",
    "    return fused_features\n",
    "\n",
    "def prepare_dataset(dataset_dir):\n",
    "    features_list = []\n",
    "    labels_list = []\n",
    "    groups_list = []\n",
    "    \n",
    "    txt_files = [f for f in os.listdir(dataset_dir) if f.endswith('.txt')]\n",
    "    print(f\"Processing {len(txt_files)} files with augmentation...\")\n",
    "    \n",
    "    for txt_file in tqdm(txt_files):\n",
    "        base_name = txt_file.split('.')[0]\n",
    "        wav_file = os.path.join(dataset_dir, base_name + '.wav')\n",
    "        if not os.path.exists(wav_file): continue\n",
    "        \n",
    "        # Load Full Audio Once\n",
    "        try:\n",
    "            full_audio, sr = librosa.load(wav_file, sr=SAMPLE_RATE)\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to load {wav_file}: {e}\")\n",
    "            continue\n",
    "\n",
    "        df_ann = pd.read_csv(os.path.join(dataset_dir, txt_file), sep='\\t', header=None, names=['start', 'end', 'crackle', 'wheeze'])\n",
    "        \n",
    "        for _, row in df_ann.iterrows():\n",
    "            if (row['end'] - row['start']) < 0.2: continue \n",
    "            \n",
    "            start_sample = int(row['start'] * sr)\n",
    "            end_sample = int(row['end'] * sr)\n",
    "            \n",
    "            # Boundary Check\n",
    "            if end_sample > len(full_audio): end_sample = len(full_audio)\n",
    "            if start_sample >= end_sample: continue\n",
    "\n",
    "            # Extract Segment\n",
    "            y_segment = full_audio[start_sample:end_sample]\n",
    "            label = get_label(row['crackle'], row['wheeze'])\n",
    "            \n",
    "            try:\n",
    "                # 1. Original (Corrected Call)\n",
    "                feat = extract_dual_features(y_segment, sr)\n",
    "                features_list.append(feat)\n",
    "                labels_list.append(label)\n",
    "                groups_list.append(base_name)\n",
    "                \n",
    "                # 2. Augmented (Corrected Call)\n",
    "                augmented_segments = augment_audio(y_segment, sr)\n",
    "                for aug_y in augmented_segments:\n",
    "                    aug_feat = extract_dual_features(aug_y, sr)\n",
    "                    features_list.append(aug_feat)\n",
    "                    labels_list.append(label)\n",
    "                    groups_list.append(base_name)\n",
    "                    \n",
    "            except Exception as e:\n",
    "                print(f\"Error processing segment in {base_name}: {e}\")\n",
    "                \n",
    "    return np.array(features_list), np.array(labels_list), np.array(groups_list)\n",
    "\n",
    "# --- 2. BUILD MODEL ---\n",
    "def build_hybrid_model(input_shape, num_classes):\n",
    "    inputs = Input(shape=input_shape)\n",
    "    \n",
    "    # CNN\n",
    "    x = Conv2D(32, kernel_size=(3, 3), padding='same')(inputs)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = ReLU()(x)\n",
    "    x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "    \n",
    "    x = Conv2D(64, kernel_size=(3, 3), padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = ReLU()(x)\n",
    "    x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "    \n",
    "    # Reshape for LSTM: (Batch, Time, Features)\n",
    "    # New Time = Original Time / 4 (due to 2 MaxPools)\n",
    "    # New Feat = Original Feat / 4 * Filters\n",
    "    target_shape = (x.shape[2], x.shape[1] * x.shape[3]) # (Time, Freq*Filters)\n",
    "    x = Reshape(target_shape)(x)\n",
    "    \n",
    "    # BiLSTM\n",
    "    x = Bidirectional(LSTM(64, return_sequences=True))(x)\n",
    "    x = Bidirectional(LSTM(32))(x)\n",
    "    \n",
    "    # Dense\n",
    "    x = Dense(64, activation='relu')(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "    outputs = Dense(num_classes, activation='softmax')(x)\n",
    "    \n",
    "    model = Model(inputs=inputs, outputs=outputs)\n",
    "    model.compile(optimizer=Adam(learning_rate=0.001),\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# --- 3. EXECUTION ---\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"--- 1. Extracting Dual Features (With Augmentation) ---\")\n",
    "    X, y_raw, groups = prepare_dataset(DATASET_DIR)\n",
    "    \n",
    "    # Safety Check\n",
    "    if len(X) == 0:\n",
    "        print(\"CRITICAL: No data loaded. Check paths.\")\n",
    "        exit()\n",
    "\n",
    "    # Encode Labels\n",
    "    le = LabelEncoder()\n",
    "    y_encoded = le.fit_transform(y_raw)\n",
    "    y_categorical = to_categorical(y_encoded)\n",
    "    \n",
    "    # Reshape X for CNN: (Batch, Height, Width, Channels)\n",
    "    # Height=103, Width=500\n",
    "    X = X[..., np.newaxis]\n",
    "    \n",
    "    print(f\"Data Shape: {X.shape}\")\n",
    "    print(f\"Labels: {le.classes_}\")\n",
    "    \n",
    "    # Grouped CV\n",
    "    kfold = StratifiedGroupKFold(n_splits=5)\n",
    "    \n",
    "    fold_acc = []\n",
    "    \n",
    "    print(\"\\n--- 2. Starting 5-Fold Grouped Cross Validation ---\")\n",
    "    \n",
    "    for fold, (train_idx, val_idx) in enumerate(kfold.split(X, y_encoded, groups=groups)):\n",
    "        print(f\"\\nTraining Fold {fold+1}...\")\n",
    "        \n",
    "        X_train, X_val = X[train_idx], X[val_idx]\n",
    "        y_train, y_val = y_categorical[train_idx], y_categorical[val_idx]\n",
    "        \n",
    "        model = build_hybrid_model(input_shape=(X.shape[1], X.shape[2], 1), num_classes=len(le.classes_))\n",
    "        \n",
    "        model.fit(X_train, y_train, validation_data=(X_val, y_val),\n",
    "                  epochs=EPOCHS, batch_size=BATCH_SIZE, verbose=1)\n",
    "        \n",
    "        # Evaluate\n",
    "        val_loss, val_acc = model.evaluate(X_val, y_val, verbose=0)\n",
    "        fold_acc.append(val_acc)\n",
    "        print(f\"Fold {fold+1} Accuracy: {val_acc:.4f}\")\n",
    "\n",
    "    print(\"\\n--- Cross-Validation Results ---\")\n",
    "    print(f\"Average Accuracy: {np.mean(fold_acc):.4f}\")\n",
    "    \n",
    "    model.save(os.path.join(SAVE_DIR, 'dual_pipeline_model_final.h5'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cf9083e-ee66-4cfe-b138-0da42226e0fb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (yolo-gpu)",
   "language": "python",
   "name": "yolo-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
